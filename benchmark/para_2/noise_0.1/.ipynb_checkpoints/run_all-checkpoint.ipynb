{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9412d5ef-0af8-47a3-a3e4-e2df7b13caf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4a0e9eda05d46c095b5eac48add0090",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/3 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aac6f7ff8af4d0daded916ad3d02484",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/3 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1589c3cf9d2d49d9acfdcbf906e18411",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/3 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d59d0d7a00e4c6da03c12d711cb386f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/3 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "PapermillExecutionError",
     "evalue": "\n---------------------------------------------------------------------------\nException encountered at \"In [2]\":\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\nCell In[2], line 213\n    211 y = pd.DataFrame(data.loc[num_point:2*num_point-2, \"n1_abs\"])\n    212 regr = linear_model.LinearRegression()\n--> 213 regr.fit(x, y)\n    214 r1_hat = regr.intercept_[0]\n    215 b12_hat = regr.coef_[0,0]\n\nFile ~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1474, in _fit_context.<locals>.decorator.<locals>.wrapper(estimator, *args, **kwargs)\n   1467     estimator._validate_params()\n   1469 with config_context(\n   1470     skip_parameter_validation=(\n   1471         prefer_skip_nested_validation or global_skip_validation\n   1472     )\n   1473 ):\n-> 1474     return fit_method(estimator, *args, **kwargs)\n\nFile ~\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:578, in LinearRegression.fit(self, X, y, sample_weight)\n    574 n_jobs_ = self.n_jobs\n    576 accept_sparse = False if self.positive else [\"csr\", \"csc\", \"coo\"]\n--> 578 X, y = self._validate_data(\n    579     X, y, accept_sparse=accept_sparse, y_numeric=True, multi_output=True\n    580 )\n    582 has_sw = sample_weight is not None\n    583 if has_sw:\n\nFile ~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:650, in BaseEstimator._validate_data(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\n    648         y = check_array(y, input_name=\"y\", **check_y_params)\n    649     else:\n--> 650         X, y = check_X_y(X, y, **check_params)\n    651     out = X, y\n    653 if not no_val_X and check_params.get(\"ensure_2d\", True):\n\nFile ~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1279, in check_X_y(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\n   1259     raise ValueError(\n   1260         f\"{estimator_name} requires y to be passed, but the target y is None\"\n   1261     )\n   1263 X = check_array(\n   1264     X,\n   1265     accept_sparse=accept_sparse,\n   (...)\n   1276     input_name=\"X\",\n   1277 )\n-> 1279 y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric, estimator=estimator)\n   1281 check_consistent_length(X, y)\n   1283 return X, y\n\nFile ~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1289, in _check_y(y, multi_output, y_numeric, estimator)\n   1287 \"\"\"Isolated part of check_X_y dedicated to y validation\"\"\"\n   1288 if multi_output:\n-> 1289     y = check_array(\n   1290         y,\n   1291         accept_sparse=\"csr\",\n   1292         force_all_finite=True,\n   1293         ensure_2d=False,\n   1294         dtype=None,\n   1295         input_name=\"y\",\n   1296         estimator=estimator,\n   1297     )\n   1298 else:\n   1299     estimator_name = _check_estimator_name(estimator)\n\nFile ~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1049, in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\n   1043     raise ValueError(\n   1044         \"Found array with dim %d. %s expected <= 2.\"\n   1045         % (array.ndim, estimator_name)\n   1046     )\n   1048 if force_all_finite:\n-> 1049     _assert_all_finite(\n   1050         array,\n   1051         input_name=input_name,\n   1052         estimator_name=estimator_name,\n   1053         allow_nan=force_all_finite == \"allow-nan\",\n   1054     )\n   1056 if copy:\n   1057     if _is_numpy_namespace(xp):\n   1058         # only make a copy if `array` and `array_orig` may share memory`\n\nFile ~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:126, in _assert_all_finite(X, allow_nan, msg_dtype, estimator_name, input_name)\n    123 if first_pass_isfinite:\n    124     return\n--> 126 _assert_all_finite_element_wise(\n    127     X,\n    128     xp=xp,\n    129     allow_nan=allow_nan,\n    130     msg_dtype=msg_dtype,\n    131     estimator_name=estimator_name,\n    132     input_name=input_name,\n    133 )\n\nFile ~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:175, in _assert_all_finite_element_wise(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\n    158 if estimator_name and input_name == \"X\" and has_nan_error:\n    159     # Improve the error message on how to handle missing values in\n    160     # scikit-learn.\n    161     msg_err += (\n    162         f\"\\n{estimator_name} does not accept missing values\"\n    163         \" encoded as NaN natively. For supervised learning, you might want\"\n   (...)\n    173         \"#estimators-that-handle-nan-values\"\n    174     )\n--> 175 raise ValueError(msg_err)\n\nValueError: Input y contains infinity or a value too large for dtype('float64').\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPapermillExecutionError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 14\u001b[0m\n\u001b[0;32m      3\u001b[0m notebooks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnoise1_ran15.ipynb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnoise1_ran20.ipynb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnoise1_seg20.ipynb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     11\u001b[0m ]\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m notebook \u001b[38;5;129;01min\u001b[39;00m notebooks:\n\u001b[1;32m---> 14\u001b[0m     pm\u001b[38;5;241m.\u001b[39mexecute_notebook(notebook, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnotebook\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\papermill\\execute.py:131\u001b[0m, in \u001b[0;36mexecute_notebook\u001b[1;34m(input_path, output_path, parameters, engine_name, request_save_on_cell_execute, prepare_only, kernel_name, language, progress_bar, log_output, stdout_file, stderr_file, start_timeout, report_mode, cwd, **engine_kwargs)\u001b[0m\n\u001b[0;32m    116\u001b[0m         nb \u001b[38;5;241m=\u001b[39m papermill_engines\u001b[38;5;241m.\u001b[39mexecute_notebook_with_engine(\n\u001b[0;32m    117\u001b[0m             engine_name,\n\u001b[0;32m    118\u001b[0m             nb,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    127\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mengine_kwargs,\n\u001b[0;32m    128\u001b[0m         )\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;66;03m# Check for errors first (it saves on error before raising)\u001b[39;00m\n\u001b[1;32m--> 131\u001b[0m     raise_for_execution_errors(nb, output_path)\n\u001b[0;32m    133\u001b[0m \u001b[38;5;66;03m# Write final output in case the engine didn't write it on cell completion.\u001b[39;00m\n\u001b[0;32m    134\u001b[0m write_ipynb(nb, output_path)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\papermill\\execute.py:251\u001b[0m, in \u001b[0;36mraise_for_execution_errors\u001b[1;34m(nb, output_path)\u001b[0m\n\u001b[0;32m    248\u001b[0m nb\u001b[38;5;241m.\u001b[39mcells\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, error_msg_cell)\n\u001b[0;32m    250\u001b[0m write_ipynb(nb, output_path)\n\u001b[1;32m--> 251\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m error\n",
      "\u001b[1;31mPapermillExecutionError\u001b[0m: \n---------------------------------------------------------------------------\nException encountered at \"In [2]\":\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\nCell In[2], line 213\n    211 y = pd.DataFrame(data.loc[num_point:2*num_point-2, \"n1_abs\"])\n    212 regr = linear_model.LinearRegression()\n--> 213 regr.fit(x, y)\n    214 r1_hat = regr.intercept_[0]\n    215 b12_hat = regr.coef_[0,0]\n\nFile ~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1474, in _fit_context.<locals>.decorator.<locals>.wrapper(estimator, *args, **kwargs)\n   1467     estimator._validate_params()\n   1469 with config_context(\n   1470     skip_parameter_validation=(\n   1471         prefer_skip_nested_validation or global_skip_validation\n   1472     )\n   1473 ):\n-> 1474     return fit_method(estimator, *args, **kwargs)\n\nFile ~\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:578, in LinearRegression.fit(self, X, y, sample_weight)\n    574 n_jobs_ = self.n_jobs\n    576 accept_sparse = False if self.positive else [\"csr\", \"csc\", \"coo\"]\n--> 578 X, y = self._validate_data(\n    579     X, y, accept_sparse=accept_sparse, y_numeric=True, multi_output=True\n    580 )\n    582 has_sw = sample_weight is not None\n    583 if has_sw:\n\nFile ~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:650, in BaseEstimator._validate_data(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\n    648         y = check_array(y, input_name=\"y\", **check_y_params)\n    649     else:\n--> 650         X, y = check_X_y(X, y, **check_params)\n    651     out = X, y\n    653 if not no_val_X and check_params.get(\"ensure_2d\", True):\n\nFile ~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1279, in check_X_y(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\n   1259     raise ValueError(\n   1260         f\"{estimator_name} requires y to be passed, but the target y is None\"\n   1261     )\n   1263 X = check_array(\n   1264     X,\n   1265     accept_sparse=accept_sparse,\n   (...)\n   1276     input_name=\"X\",\n   1277 )\n-> 1279 y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric, estimator=estimator)\n   1281 check_consistent_length(X, y)\n   1283 return X, y\n\nFile ~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1289, in _check_y(y, multi_output, y_numeric, estimator)\n   1287 \"\"\"Isolated part of check_X_y dedicated to y validation\"\"\"\n   1288 if multi_output:\n-> 1289     y = check_array(\n   1290         y,\n   1291         accept_sparse=\"csr\",\n   1292         force_all_finite=True,\n   1293         ensure_2d=False,\n   1294         dtype=None,\n   1295         input_name=\"y\",\n   1296         estimator=estimator,\n   1297     )\n   1298 else:\n   1299     estimator_name = _check_estimator_name(estimator)\n\nFile ~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1049, in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\n   1043     raise ValueError(\n   1044         \"Found array with dim %d. %s expected <= 2.\"\n   1045         % (array.ndim, estimator_name)\n   1046     )\n   1048 if force_all_finite:\n-> 1049     _assert_all_finite(\n   1050         array,\n   1051         input_name=input_name,\n   1052         estimator_name=estimator_name,\n   1053         allow_nan=force_all_finite == \"allow-nan\",\n   1054     )\n   1056 if copy:\n   1057     if _is_numpy_namespace(xp):\n   1058         # only make a copy if `array` and `array_orig` may share memory`\n\nFile ~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:126, in _assert_all_finite(X, allow_nan, msg_dtype, estimator_name, input_name)\n    123 if first_pass_isfinite:\n    124     return\n--> 126 _assert_all_finite_element_wise(\n    127     X,\n    128     xp=xp,\n    129     allow_nan=allow_nan,\n    130     msg_dtype=msg_dtype,\n    131     estimator_name=estimator_name,\n    132     input_name=input_name,\n    133 )\n\nFile ~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:175, in _assert_all_finite_element_wise(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\n    158 if estimator_name and input_name == \"X\" and has_nan_error:\n    159     # Improve the error message on how to handle missing values in\n    160     # scikit-learn.\n    161     msg_err += (\n    162         f\"\\n{estimator_name} does not accept missing values\"\n    163         \" encoded as NaN natively. For supervised learning, you might want\"\n   (...)\n    173         \"#estimators-that-handle-nan-values\"\n    174     )\n--> 175 raise ValueError(msg_err)\n\nValueError: Input y contains infinity or a value too large for dtype('float64').\n"
     ]
    }
   ],
   "source": [
    "import papermill as pm\n",
    "\n",
    "notebooks = [\n",
    "    #\"noise1_ran15.ipynb\",\n",
    "    #\"noise1_ran20.ipynb\",\n",
    "    #\"noise1_ran5.ipynb\",\n",
    "    \"noise1_seg01.ipynb\",\n",
    "    \"noise1_seg05.ipynb\",\n",
    "    \"noise1_seg10.ipynb\",\n",
    "    \"noise1_seg20.ipynb\"\n",
    "]\n",
    "\n",
    "for notebook in notebooks:\n",
    "    pm.execute_notebook(notebook, f\"output_{notebook}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b1550b-a1a5-4cef-8438-238bb78db5b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
